{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nAs of 2021, there are eight official planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. Pluto was previously considered a planet, but it was reclassified as a dwarf planet in 2006. There may be other planets outside of our solar system, but they have not been officially confirmed.',\n",
       " 'There are 8 planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diff of llm and chatAi\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# text-davinchi-003 is stopped\n",
    "llm = OpenAI(model_name = \"gpt-3.5-turbo-instruct\")\n",
    "# model_name = \"gpt-3.5-turbo\"\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "a = llm.predict(\"How many planets are there?\")\n",
    "b = chat.predict(\"How many planets are there?\")\n",
    "\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국과 태국 사이의 거리는 약 3,300km입니다. 제 이름은 정팔입니다. 어떻게 도와드릴까요?')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}\")\n",
    "\n",
    "# chatAi options\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# hard code message\n",
    "#messages = [\n",
    "#   SystemMessage(content= \"You are a geography expert. And you only reply in korean\"),\n",
    "#   AIMessage(content= \"안녕하세요 내 친구여\"),\n",
    "#   HumanMessage(content= \"what is the distance between Korea and Italy. Also what is your name?\")\n",
    "#]\n",
    "\n",
    "#chat.predict_messages(messages)\n",
    "\n",
    "messages = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert. And you only reply in {language}\"),\n",
    "        (\"ai\", \"안녕하세요 내 친구여 저는 {name}이라 합니다\"),\n",
    "        (\"human\", \"what is the distance between {country_a} and {country_b}. Also what is your name?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "#prompt = template.format(country_a = \"Japan\", country_b = \"America\")\n",
    "#chat.predict(prompt)\n",
    "\n",
    "prompt = messages.format_messages(\n",
    "    language = \"Korean\",\n",
    "    name = \"Jung pal\",\n",
    "    country_a = \"Korea\",\n",
    "    country_b = \"Thailand\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "#p.parse(\"Hello, how, are, you\")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items}. And do not reply with anything else.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items = 10,\n",
    "    question = \"What are the planets?\"\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pikachu', 'Charizard', 'Bulbasaur', 'Squirtle', 'Jigglypuff']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain all upper operation\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\": 5,\n",
    "    \"question\": \"What are the pocket monsters\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
